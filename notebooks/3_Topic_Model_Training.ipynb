{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "31b17f54-6bfd-48da-ade1-d08773cc47f1"
    }
   },
   "source": [
    "# Automatic Learning of Key Phrases and Topics in Document Collections\n",
    "\n",
    "## Part 3: Topic Modeling Training and Summarization\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook is Part 3 of 6, in a series providing a step-by-step description of how to process and analyze the contents of a large collection of text documents in an unsupervised manner. Using Python packages and custom code examples, we have implemented the basic framework that combines key phrase learning and latent topic modeling as described in the paper entitled [\"Modeling Multiword Phrases with Constrained Phrases Tree for Improved Topic Modeling of Conversational Speech\"](http://people.csail.mit.edu/hazen/publications/Hazen-SLT-2012.pdf) which was originally presented in the 2012 IEEE Workshop on Spoken Language Technology.\n",
    "\n",
    "Although the paper examines the use of the technology for analyzing human-to-human conversations, the techniques are quite general and can be applied to a wide range natural language data including news stories, legal documents, research publications, social media forum discussion, customer feedback forms, product reviews, and many more.\n",
    "\n",
    "Part 3 of the series shows how to train a topic model on a collection of text documents and how to use the topic model to summarize the contents of the corpus. The training is applied to text generated from the preprocessing and phrase learning stages presented in Parts 1 and 2.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "21d8d7fd-501d-4eec-abd4-a827100e5406"
    }
   },
   "source": [
    "### Import Relevant Python Packages\n",
    "\n",
    "Most significantly, Part 3 relies on the use of the [Gensim Python library](http://radimrehurek.com/gensim/)  for generating a sparse bag-of-words representation of each document and then training a [Latent Dirichlet Allocation (LDA)](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) model on the data. LDA produces a collection of latent topics learned in a completely unsupervised fashion from the text data. Each document can then be represented with a distribution of the learned topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "23d9b7ef-11db-419b-9f97-7bb07a1e3ca5"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.logging.script_run_request.ScriptRunRequest at 0x2000c4fa940>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas \n",
    "import re\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from operator import itemgetter\n",
    "from collections import namedtuple\n",
    "import time\n",
    "import gc\n",
    "import sys\n",
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "from azureml.logging import get_azureml_logger\n",
    "aml_logger = get_azureml_logger()   # logger writes to AMLWorkbench runtime view\n",
    "aml_logger.log('amlrealworld.document-collection-analysis.notebook3', 'true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "44f6c13e-aae6-4bcf-97f5-5527bacc0512"
    }
   },
   "source": [
    "### Load Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE** The data file is saved under the folder defined by environment variable `AZUREML_NATIVE_SHARE_DIRECTORY` in notebook 1. If you have changed it to `../Data`, please also do the change here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "46697539-829d-406f-8722-7b4f7ec3beee"
    }
   },
   "outputs": [],
   "source": [
    "# Load full TSV file including a column of text\n",
    "frame = pandas.read_csv(os.path.join(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'], \"CongressionalDocsProcessed.tsv\"), \n",
    "                        sep='\\t',\n",
    "                        encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "fb58ed5d-85bb-4ab3-9b8e-2d8b79d2df55"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total docs in corpus: 297462\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>ProcessedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hconres1-93</td>\n",
       "      <td>provides that effective from january_3 1973 th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hconres2-93</td>\n",
       "      <td>makes_it_the_sense_of_the_congress that the po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hconres3-93</td>\n",
       "      <td>establishes a joint congressional_committee on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hconres4-93</td>\n",
       "      <td>makes_it_the_sense_of_the_congress that the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hconres5-93</td>\n",
       "      <td>makes_it_the_sense_of_the_congress that the co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DocID                                      ProcessedText\n",
       "0  hconres1-93  provides that effective from january_3 1973 th...\n",
       "1  hconres2-93  makes_it_the_sense_of_the_congress that the po...\n",
       "2  hconres3-93  establishes a joint congressional_committee on...\n",
       "3  hconres4-93  makes_it_the_sense_of_the_congress that the pr...\n",
       "4  hconres5-93  makes_it_the_sense_of_the_congress that the co..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Total docs in corpus: %d\\n\" % len(frame))\n",
    "\n",
    "# Show the first five rows of the data in the frame\n",
    "frame[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bc5ecdb1-c51c-457f-be3f-eee94247f13b"
    }
   },
   "source": [
    "### Load the Stop Word Lists\n",
    "Latent topic models attempt to restrict the topic learning processing to the use of only content bearing words by excluding non-content bearing <b><i>stop words</i></b>. Manually crafted stop word lists are typically manually crafted and include common functional words such as articles, conjunctions, prepositions, pronouns, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "8a9b81d1-058f-4a37-acbe-b825045866b4"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function for loading lists into dictionary hash tables\n",
    "def LoadListAsHash(filename):\n",
    "    listHash = {}\n",
    "    fp = open(filename, encoding='utf-8')\n",
    "\n",
    "    # Read in lines one by one stripping away extra spaces, \n",
    "    # leading spaces, and trailing spaces and inserting each\n",
    "    # cleaned up line into a hash table\n",
    "    re1 = re.compile(' +')\n",
    "    re2 = re.compile('^ +| +$')\n",
    "    for stringIn in fp.readlines():\n",
    "        term = re2.sub(\"\", re1.sub(\" \", stringIn.strip('\\n')))\n",
    "        if term != '':\n",
    "            listHash[term] = 1\n",
    "\n",
    "    fp.close()\n",
    "    return listHash "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "bc5e3810-08b3-41aa-af97-0159bf9be597"
    }
   },
   "outputs": [],
   "source": [
    "# Load the stop-list of non-content bearing function words\n",
    "stopwordHash = LoadListAsHash(os.path.join(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'], \"function_words.txt\"))\n",
    "\n",
    "# Additional words can also be manually added to the stop word list as needed\n",
    "stopwordHash[\"foo\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c3593bde-7eee-4a9d-8565-7d9774947404"
    }
   },
   "source": [
    "### Load the Mapping of Lower-Cased Vocabulary Items to Their Most Common Surface Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "21678e5f-ad6c-46d1-8a71-f64bd9483c42"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Bad line in surface form mapping file:  \t \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load surface form mappings here\n",
    "fp = open(os.path.join(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'], \"Vocab2SurfaceFormMapping.tsv\"), \n",
    "          encoding='utf-8')\n",
    "\n",
    "vocabToSurfaceFormHash = {}\n",
    "\n",
    "# Each line in the file has two tab separated fields;\n",
    "# the first is the vocabulary item used during modeling\n",
    "# and the second is its most common surface form in the \n",
    "# original data\n",
    "for stringIn in fp.readlines():\n",
    "    fields = stringIn.strip().split(\"\\t\")\n",
    "    if len(fields) != 2:\n",
    "        print (\"Warning: Bad line in surface form mapping file: %s\" % stringIn)\n",
    "    elif fields[0] == \"\" or fields[1] == \"\":\n",
    "        print (\"Warning: Bad line in surface form mapping file: %s\" % stringIn)\n",
    "    else:\n",
    "        vocabToSurfaceFormHash[fields[0]] = fields[1]\n",
    "fp.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4ddff9a8-0a31-4889-bedb-b64d10eddcc1"
    }
   },
   "source": [
    "### Do Topic Modeling on Corpus using Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "177ee67d-3e38-4009-b65e-4d08f79c862b"
    }
   },
   "source": [
    "#### Create the Vocabulary Used for Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "55d8b0a5-11a9-4cf1-8399-b2d036254dd0"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting words\n",
      "Building vocab\n",
      "Excluded 297 stop words\n",
      "Excluded 18501 non-alphabetic words\n",
      "Excluded 70004 words below word count threshold\n",
      "Excluded 276 words below doc count threshold\n",
      "Excluded 1 words above max doc frequency\n",
      "Final Vocab Size: 68145 words\n"
     ]
    }
   ],
   "source": [
    "def CreateVocabForTopicModeling(textData,stopwordHash):\n",
    "\n",
    "    print (\"Counting words\")\n",
    "    numDocs = len(textData) \n",
    "    globalWordCountHash = {} \n",
    "    globalDocCountHash = {} \n",
    "    for textLine in textData:\n",
    "        docWordCountHash = {}\n",
    "        for word in str(textLine).split():\n",
    "            if word in globalWordCountHash:\n",
    "                globalWordCountHash[word] += 1\n",
    "            else:\n",
    "                globalWordCountHash[word] = 1\n",
    "            if word not in docWordCountHash: \n",
    "                docWordCountHash[word] = 1\n",
    "                if word in globalDocCountHash:\n",
    "                    globalDocCountHash[word] += 1\n",
    "                else:\n",
    "                    globalDocCountHash[word] = 1\n",
    "\n",
    "    minWordCount = 5;\n",
    "    minDocCount = 2;\n",
    "    maxDocFreq = .25;\n",
    "    vocabCount = 0;\n",
    "    vocabHash = {}\n",
    "\n",
    "    excStopword = 0\n",
    "    excNonalphabetic = 0\n",
    "    excMinwordcount = 0\n",
    "    excNotindochash = 0\n",
    "    excMindoccount = 0\n",
    "    excMaxdocfreq =0\n",
    "\n",
    "    print (\"Building vocab\")\n",
    "    for word in globalWordCountHash.keys():\n",
    "        # Test vocabulary exclusion criteria for each word\n",
    "        if ( word in stopwordHash ):\n",
    "            excStopword += 1\n",
    "        elif ( not re.search(r'[a-zA-Z]', word, 0) ):\n",
    "            excNonalphabetic += 1\n",
    "        elif ( globalWordCountHash[word] < minWordCount ):\n",
    "            excMinwordcount += 1\n",
    "        elif ( word not in globalDocCountHash ):\n",
    "            print (\"Warning: Word '%s' not in doc count hash\") % (word)\n",
    "            excNotindochash += 1\n",
    "        elif ( globalDocCountHash[word] < minDocCount ):\n",
    "            excMindoccount += 1\n",
    "        elif ( float(globalDocCountHash[word])/float(numDocs) > maxDocFreq ):\n",
    "            excMaxdocfreq += 1\n",
    "        else:\n",
    "            # Add word to vocab\n",
    "            vocabHash[word]= globalWordCountHash[word];\n",
    "            vocabCount += 1 \n",
    "    print (\"Excluded %d stop words\" % (excStopword))       \n",
    "    print (\"Excluded %d non-alphabetic words\" % (excNonalphabetic))  \n",
    "    print (\"Excluded %d words below word count threshold\" % (excMinwordcount)) \n",
    "    print (\"Excluded %d words below doc count threshold\" % (excMindoccount))\n",
    "    print (\"Excluded %d words above max doc frequency\" % (excMaxdocfreq)) \n",
    "    print (\"Final Vocab Size: %d words\" % vocabCount)\n",
    "            \n",
    "    return vocabHash\n",
    "                    \n",
    "vocabHash = CreateVocabForTopicModeling(frame['ProcessedText'], stopwordHash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the stop word \"and\" is not the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbpresent": {
     "id": "8e615a03-a616-4ce6-aaed-149bb7dc6c41"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'and' in vocabHash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a learned phrase is in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbpresent": {
     "id": "1301be86-24d2-45a3-aced-d0b4948e765b"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'department_of_labor' in vocabHash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary hash table contains the total count of the vocabulary item in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbpresent": {
     "id": "e537aed2-414b-4e59-be59-5cee147398b5"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1944"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabHash[\"department_of_labor\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the 10 most frequent non-excluded words in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbpresent": {
     "id": "22d6a20f-fa82-4df0-8aac-29c150397a1f"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('requires', 129566),\n",
       " ('provides', 102427),\n",
       " ('state', 98103),\n",
       " ('program', 96471),\n",
       " ('including', 74228),\n",
       " ('certain', 68231),\n",
       " ('provide', 66405),\n",
       " ('programs', 62842),\n",
       " ('united_states', 62605),\n",
       " ('states', 56722)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(vocabHash.items(), key=lambda x: -x[1])[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1940dcd6-9b8b-4dea-af39-ca75e72062aa"
    }
   },
   "source": [
    "#### Convert the Text Data Into a Sparse Vector Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "6244226e-a91b-4767-83da-d41e882399a4"
    }
   },
   "outputs": [],
   "source": [
    "# Start by tokenizing the full text string for each document into list of tokens\n",
    "# Any token that is in not in the pre-defined set of acceptable vocabulary words is excluded\n",
    "def TokenizeText(textData,vocabHash):\n",
    "    tokenizedText = []\n",
    "        \n",
    "    for textLine in textData:\n",
    "        tokenizedText.append([token for token in str(textLine).split() if token in vocabHash])    \n",
    "    return tokenizedText\n",
    "    \n",
    "tokenizedDocs = TokenizeText(frame['ProcessedText'], vocabHash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the tokenizaton of the first two documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbpresent": {
     "id": "f28084b0-cc2e-4231-842f-5765d92d44f0"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['provides',\n",
       "  'effective',\n",
       "  'january_3',\n",
       "  'joint_committee',\n",
       "  'created',\n",
       "  'make',\n",
       "  'necessary',\n",
       "  'arrangements',\n",
       "  'inauguration',\n",
       "  'president-elect_and_vice_president-elect',\n",
       "  'united_states',\n",
       "  '20th',\n",
       "  'day',\n",
       "  'january',\n",
       "  'continued',\n",
       "  'purpose',\n",
       "  'power',\n",
       "  'authority',\n",
       "  'conferred',\n",
       "  'senate',\n",
       "  'concurrent_resolution',\n",
       "  'ninety-second',\n",
       "  'congress'],\n",
       " ['makes_it_the_sense_of_the_congress',\n",
       "  'pollution',\n",
       "  'waters',\n",
       "  'all',\n",
       "  'world',\n",
       "  'matter',\n",
       "  'vital',\n",
       "  'concern',\n",
       "  'all_nations',\n",
       "  'dealt',\n",
       "  'matter',\n",
       "  'highest_priority',\n",
       "  'makes_it_the_sense_of_the_congress',\n",
       "  'president',\n",
       "  'acting',\n",
       "  'united_states',\n",
       "  'delegation',\n",
       "  'united',\n",
       "  'national_conference',\n",
       "  'human_environment',\n",
       "  'steps',\n",
       "  'necessary',\n",
       "  'propose',\n",
       "  'international_agreement',\n",
       "  'amendments',\n",
       "  'existing',\n",
       "  'international_agreements',\n",
       "  'appropriate',\n",
       "  'providing',\n",
       "  'coordinated',\n",
       "  'international',\n",
       "  'activites',\n",
       "  'prohibit',\n",
       "  'disposal',\n",
       "  'munitions',\n",
       "  'chemicals',\n",
       "  'chemical_munitions',\n",
       "  'military',\n",
       "  'material',\n",
       "  'pollutants',\n",
       "  'territorial_waters',\n",
       "  'contiguous',\n",
       "  'zones',\n",
       "  'deep_seabed',\n",
       "  'international',\n",
       "  'waters',\n",
       "  'prevent',\n",
       "  'pollution',\n",
       "  'waters',\n",
       "  'world']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizedDocs[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the total number of vocabulary tokens used over the entire corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbpresent": {
     "id": "c158c2fc-56b7-40a7-a765-d7a3b4692839"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of retained tokens: 22649513\n"
     ]
    }
   ],
   "source": [
    "numTokens = 0\n",
    "\n",
    "for i in range(0,len(tokenizedDocs)):\n",
    "    numTokens += len(tokenizedDocs[i])\n",
    "print(\"Total number of retained tokens: %d\" % numTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "be794056-435f-49e2-b69b-2ca5409710bf"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary mapping string tokens in the text to unique token IDs\n",
    "dictionary = corpora.Dictionary(tokenizedDocs)\n",
    "\n",
    "# If the reverse mapping for token ids back to string doesn't exist then create the mapping\n",
    "# in the form of a list where the list index is the tokenID and the list value is the token\n",
    "if len(dictionary.id2token) == 0:\n",
    "    numTokens = len(dictionary.token2id);\n",
    "    id2token = numTokens * [\"\"];\n",
    "    for token in dictionary.token2id:\n",
    "        tokenID = dictionary.token2id[token]\n",
    "        if tokenID < numTokens:\n",
    "            id2token[tokenID] = token\n",
    "        else: \n",
    "            print (\"Warning: token id %d for token '%s' exceeds max index of %d\" % (tokenID,token,numTopics-1))\n",
    "    for i in range(0,numTokens):\n",
    "        if id2token[i] == \"\":\n",
    "            print (\"Warning: token id %d has an empty token\" % i)\n",
    "else:\n",
    "    id2token = dictionary.id2token\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbpresent": {
     "id": "eaf0b191-c85a-48b9-9bcb-b38ca076c9b4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ID 0 --> day\n",
      "Token ID 1 --> necessary\n",
      "Token ID 2 --> purpose\n",
      "Token ID 3 --> created\n",
      "Token ID 4 --> effective\n",
      "Token ID 5 --> president-elect_and_vice_president-elect\n",
      "Token ID 6 --> joint_committee\n",
      "Token ID 7 --> january_3\n",
      "Token ID 8 --> ninety-second\n",
      "Token ID 9 --> power\n",
      "\n",
      "spent --> Token ID 9046\n"
     ]
    }
   ],
   "source": [
    "# The mapping from unique token ids to strings uses the id2token element of the dictionary\n",
    "for i in range(0, 10):\n",
    "    print (\"Token ID %d --> %s\" % (i, id2token[i]))\n",
    "\n",
    "# The mapping from strings to unique token ids uses the token2id element of the dictionary   \n",
    "print (\"\")\n",
    "print (\"%s --> Token ID %d\" % ('spent', dictionary.token2id['spent']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Gensim corpus structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "bcd1daea-0849-4cd4-9349-a7f52641eb95"
    }
   },
   "outputs": [],
   "source": [
    "corpus =[dictionary.doc2bow(tokens) for tokens in tokenizedDocs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the corpus structure models the tokenized text as a sparse list of the tokens in the document where each list item is represented by the unique ID for the token along with the count of how often that token appeared in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbpresent": {
     "id": "1f6a12bd-9325-457d-83d0-9e374033e64f"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['makes_it_the_sense_of_the_congress', 'pollution', 'waters', 'all', 'world', 'matter', 'vital', 'concern', 'all_nations', 'dealt', 'matter', 'highest_priority', 'makes_it_the_sense_of_the_congress', 'president', 'acting', 'united_states', 'delegation', 'united', 'national_conference', 'human_environment', 'steps', 'necessary', 'propose', 'international_agreement', 'amendments', 'existing', 'international_agreements', 'appropriate', 'providing', 'coordinated', 'international', 'activites', 'prohibit', 'disposal', 'munitions', 'chemicals', 'chemical_munitions', 'military', 'material', 'pollutants', 'territorial_waters', 'contiguous', 'zones', 'deep_seabed', 'international', 'waters', 'prevent', 'pollution', 'waters', 'world']\n",
      "spent: 9046\n",
      "[(1, 1), (18, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 2), (29, 1), (30, 1), (31, 2), (32, 1), (33, 1), (34, 2), (35, 2), (36, 1), (37, 1), (38, 3), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 2), (62, 1), (63, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizedDocs[1])\n",
    "print(\"spent:\", dictionary.token2id['spent'])\n",
    "print (corpus[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a0086b4c-7e4a-4bc7-b720-7ef6bf2508ad"
    }
   },
   "source": [
    "#### Train an LDA Topic Model Using the Gensim Package "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out how many CPU cores on the compute context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of CPUs: 8\n"
     ]
    }
   ],
   "source": [
    "numCPUs = multiprocessing.cpu_count()\n",
    "print (\"Total number of CPUs:\", numCPUs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE:** The execution time to train an LDA topic model depends on multiple factors such as the size of corpus, hyper parameter configuration, as well as the number of cores on the machine. Using multiple CPU cores trains a model faster. However, with the same hyper parameter setting more cores means fewer updates during training. It is recommended to have **at least 100 updates to train a converged LDA model**. The relationship between number of updates and hyper parameters is discussed in this post and this post. In our tests, it took about 3 hours to train an LDA model with 200 topics using the configuration of `workers=15`, `passes=10`, `chunksize=1000` on a machine with 16 cores (2.0 GHz).\n",
    "\n",
    "> By default, it will learn a LDA model with 200 topics. If you just need to try it, change the variable `numTopics` to a smaller number, but be careful since it may affect the execution of other downstream notebooks.\n",
    "\n",
    "> **Note that if you re-train the LDA model, you may not exactly get the same LDA topic model due the randomazation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "4d17de12-2451-4b0b-ab3b-a73bf7f6e9dc"
    }
   },
   "outputs": [],
   "source": [
    "# Set the number of topics to be learned to 200\n",
    "numTopics=200\n",
    "\n",
    "if numCPUs > 1:\n",
    "    numWorkers = numCPUs - 1\n",
    "else:\n",
    "    numWorkers = 1\n",
    "numIterations = 2000\n",
    "\n",
    "# Train LDA model \n",
    "\n",
    "# If you want to train a new LDA model from scratch then set this if statement to 'True'\n",
    "retrain = True\n",
    "\n",
    "if retrain:\n",
    "    # If we only have one core available use standard training\n",
    "    if numWorkers == 1:\n",
    "        lda = gensim.models.ldamodel.LdaModel(corpus, \n",
    "                                              id2word=dictionary, \n",
    "                                              num_topics=numTopics, \n",
    "                                              iterations=numIterations,\n",
    "                                              passes=5,\n",
    "                                              chunksize=1000,\n",
    "                                              random_state=1,\n",
    "                                              offset=1.0)\n",
    "   \n",
    "    # If we have multiple cores available, then use distributed multi-core training\n",
    "    if numWorkers > 1:\n",
    "        lda = gensim.models.ldamulticore.LdaMulticore(corpus, \n",
    "                                                      id2word=dictionary, \n",
    "                                                      num_topics=numTopics,\n",
    "                                                      iterations=numIterations,\n",
    "                                                      workers = numWorkers,\n",
    "                                                      passes=5,\n",
    "                                                      chunksize=1000,\n",
    "                                                      random_state=1,\n",
    "                                                      offset=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c96b2d58-4729-4243-8799-c21dc615fa58"
    }
   },
   "outputs": [],
   "source": [
    "# Saving and loading a trained LDA model\n",
    "ldaFile = os.path.join(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'], \"CongressionalDocsLDA.pickle\")\n",
    "\n",
    "# To save a newly trained model to file set this to 'True'\n",
    "if retrain:\n",
    "    #Save a trained LDA model\n",
    "    lda.save(ldaFile)\n",
    "\n",
    "# This will load a pre-existing LDA model from file...set it to 'False' to use a newly trained model instead   \n",
    "else:\n",
    "    # Loaded trained model\n",
    "    lda = gensim.models.ldamodel.LdaModel.load(ldaFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d3b757c3-d523-4bc0-80af-7be110f7a46e"
    }
   },
   "source": [
    "#### Accessing the Contents of the LDA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the accessible variables in the LDA model structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbpresent": {
     "id": "96008087-cb6e-4ba1-b9c6-b4480835ef0f"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__ignoreds': ['dispatcher', 'state', 'id2word'],\n",
       " '__numpys': ['expElogbeta'],\n",
       " '__recursive_saveloads': [],\n",
       " '__scipys': [],\n",
       " 'alpha': array([ 0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,\n",
       "         0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005,  0.005]),\n",
       " 'batch': False,\n",
       " 'chunksize': 1000,\n",
       " 'decay': 0.5,\n",
       " 'dispatcher': None,\n",
       " 'distributed': False,\n",
       " 'eta': array([ 0.005,  0.005,  0.005, ...,  0.005,  0.005,  0.005]),\n",
       " 'eval_every': 10,\n",
       " 'expElogbeta': array([[  1.43134412e-06,   8.78255518e-04,   9.71925871e-05, ...,\n",
       "           9.15574105e-93,   4.12040520e-93,   4.12040520e-93],\n",
       "        [  4.32625994e-09,   2.61696532e-04,   7.03691811e-31, ...,\n",
       "           6.23015456e-93,   6.23015456e-93,   6.23015456e-93],\n",
       "        [  7.12095848e-16,   2.89361173e-04,   5.16696672e-05, ...,\n",
       "           9.56673484e-93,   9.56673484e-93,   9.56673484e-93],\n",
       "        ..., \n",
       "        [  2.86695950e-55,   1.46680854e-04,   2.00732719e-03, ...,\n",
       "           1.63108687e-92,   1.63108687e-92,   1.63108687e-92],\n",
       "        [  1.55642074e-74,   3.47334741e-06,   6.41545924e-93, ...,\n",
       "           6.41545924e-93,   6.41545924e-93,   6.41545924e-93],\n",
       "        [  9.16643663e-93,   1.85719354e-04,   2.96036398e-04, ...,\n",
       "           1.02040359e-92,   9.16643663e-93,   9.16643663e-93]]),\n",
       " 'gamma_threshold': 0.001,\n",
       " 'id2word': <gensim.corpora.dictionary.Dictionary at 0x1a705cbb6d8>,\n",
       " 'iterations': 2000,\n",
       " 'minimum_phi_value': 0.01,\n",
       " 'minimum_probability': 0.01,\n",
       " 'num_terms': 68145,\n",
       " 'num_topics': 200,\n",
       " 'num_updates': 297462,\n",
       " 'numworkers': 1,\n",
       " 'offset': 1.0,\n",
       " 'optimize_alpha': False,\n",
       " 'optimize_eta': False,\n",
       " 'passes': 5,\n",
       " 'per_word_topics': False,\n",
       " 'random_state': <mtrand.RandomState at 0x1a705ca95e8>,\n",
       " 'state': <gensim.models.ldamodel.LdaState at 0x1a6980232e8>,\n",
       " 'update_every': 1,\n",
       " 'workers': 7}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print out the internal help document for the LDA model class you can use the help() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbpresent": {
     "id": "2a72aece-5261-4bad-883b-b21455f957cc"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LdaMulticore in module gensim.models.ldamulticore object:\n",
      "\n",
      "class LdaMulticore(gensim.models.ldamodel.LdaModel)\n",
      " |  The constructor estimates Latent Dirichlet Allocation model parameters based\n",
      " |  on a training corpus:\n",
      " |  \n",
      " |  >>> lda = LdaMulticore(corpus, num_topics=10)\n",
      " |  \n",
      " |  You can then infer topic distributions on new, unseen documents, with\n",
      " |  \n",
      " |  >>> doc_lda = lda[doc_bow]\n",
      " |  \n",
      " |  The model can be updated (trained) with new documents via\n",
      " |  \n",
      " |  >>> lda.update(other_corpus)\n",
      " |  \n",
      " |  Model persistency is achieved through its `load`/`save` methods.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LdaMulticore\n",
      " |      gensim.models.ldamodel.LdaModel\n",
      " |      gensim.interfaces.TransformationABC\n",
      " |      gensim.utils.SaveLoad\n",
      " |      gensim.models.basemodel.BaseTopicModel\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, corpus=None, num_topics=100, id2word=None, workers=None, chunksize=2000, passes=1, batch=False, alpha='symmetric', eta=None, decay=0.5, offset=1.0, eval_every=10, iterations=50, gamma_threshold=0.001, random_state=None, minimum_probability=0.01, minimum_phi_value=0.01, per_word_topics=False)\n",
      " |      If given, start training from the iterable `corpus` straight away. If not given,\n",
      " |      the model is left untrained (presumably because you want to call `update()` manually).\n",
      " |      \n",
      " |      `num_topics` is the number of requested latent topics to be extracted from\n",
      " |      the training corpus.\n",
      " |      \n",
      " |      `id2word` is a mapping from word ids (integers) to words (strings). It is\n",
      " |      used to determine the vocabulary size, as well as for debugging and topic\n",
      " |      printing.\n",
      " |      \n",
      " |      `workers` is the number of extra processes to use for parallelization. Uses\n",
      " |      all available cores by default: `workers=cpu_count()-1`. **Note**: for\n",
      " |      hyper-threaded CPUs, `cpu_count()` returns a useless number -- set `workers`\n",
      " |      directly to the number of your **real** cores (not hyperthreads) minus one,\n",
      " |      for optimal performance.\n",
      " |      \n",
      " |      If `batch` is not set, perform online training by updating the model once\n",
      " |      every `workers * chunksize` documents (online training). Otherwise,\n",
      " |      run batch LDA, updating model only once at the end of each full corpus pass.\n",
      " |      \n",
      " |      `alpha` and `eta` are hyperparameters that affect sparsity of the document-topic\n",
      " |      (theta) and topic-word (lambda) distributions. Both default to a symmetric\n",
      " |      1.0/num_topics prior.\n",
      " |      \n",
      " |      `alpha` can be set to an explicit array = prior of your choice. It also\n",
      " |      support special values of 'asymmetric' and 'auto': the former uses a fixed\n",
      " |      normalized asymmetric 1.0/topicno prior, the latter learns an asymmetric\n",
      " |      prior directly from your data.\n",
      " |      \n",
      " |      `eta` can be a scalar for a symmetric prior over topic/word\n",
      " |      distributions, or a matrix of shape num_topics x num_words,\n",
      " |      which can be used to impose asymmetric priors over the word\n",
      " |      distribution on a per-topic basis. This may be useful if you\n",
      " |      want to seed certain topics with particular words by boosting\n",
      " |      the priors for those words.\n",
      " |      \n",
      " |      Calculate and log perplexity estimate from the latest mini-batch once every\n",
      " |      `eval_every` documents. Set to `None` to disable perplexity estimation (faster),\n",
      " |      or to `0` to only evaluate perplexity once, at the end of each corpus pass.\n",
      " |      \n",
      " |      `decay` and `offset` parameters are the same as Kappa and Tau_0 in\n",
      " |      Hoffman et al, respectively.\n",
      " |      \n",
      " |      `random_state` can be a numpy.random.RandomState object or the seed for one\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      >>> lda = LdaMulticore(corpus, id2word=id2word, num_topics=100)  # train model\n",
      " |      >>> print(lda[doc_bow]) # get topic probability distribution for a document\n",
      " |      >>> lda.update(corpus2) # update the LDA model with additional documents\n",
      " |      >>> print(lda[doc_bow])\n",
      " |  \n",
      " |  update(self, corpus, chunks_as_numpy=False)\n",
      " |      Train the model with new documents, by EM-iterating over `corpus` until\n",
      " |      the topics converge (or until the maximum number of allowed iterations\n",
      " |      is reached). `corpus` must be an iterable (repeatable stream of documents),\n",
      " |      \n",
      " |      The E-step is distributed into the several processes.\n",
      " |      \n",
      " |      This update also supports updating an already trained model (`self`)\n",
      " |      with new documents from `corpus`; the two models are then merged in\n",
      " |      proportion to the number of old vs. new documents. This feature is still\n",
      " |      experimental for non-stationary input streams.\n",
      " |      \n",
      " |      For stationary input (no topic drift in new documents), on the other hand,\n",
      " |      this equals the online update of Hoffman et al. and is guaranteed to\n",
      " |      converge for any `decay` in (0.5, 1.0>.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __slotnames__ = []\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gensim.models.ldamodel.LdaModel:\n",
      " |  \n",
      " |  __getitem__(self, bow, eps=None)\n",
      " |      Return topic distribution for the given document `bow`, as a list of\n",
      " |      (topic_id, topic_probability) 2-tuples.\n",
      " |      \n",
      " |      Ignore topics with very low probability (below `eps`).\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  bound(self, corpus, gamma=None, subsample_ratio=1.0)\n",
      " |      Estimate the variational bound of documents from `corpus`:\n",
      " |      E_q[log p(corpus)] - E_q[log q(corpus)]\n",
      " |      \n",
      " |      `gamma` are the variational parameters on topic weights for each `corpus`\n",
      " |      document (=2d matrix=what comes out of `inference()`).\n",
      " |      If not supplied, will be inferred from the model.\n",
      " |  \n",
      " |  clear(self)\n",
      " |      Clear model state (free up some memory). Used in the distributed algo.\n",
      " |  \n",
      " |  diff(self, other, distance='kullback_leibler', num_words=100, n_ann_terms=10, normed=True)\n",
      " |      Calculate difference topic2topic between two Lda models\n",
      " |      `other` instances of `LdaMulticore` or `LdaModel`\n",
      " |      `distance` is function that will be applied to calculate difference between any topic pair.\n",
      " |      Available values: `kullback_leibler`, `hellinger` and `jaccard`\n",
      " |      `num_words` is quantity of most relevant words that used if distance == `jaccard` (also used for annotation)\n",
      " |      `n_ann_terms` is max quantity of words in intersection/symmetric difference between topics (used for annotation)\n",
      " |      Returns a matrix Z with shape (m1.num_topics, m2.num_topics), where Z[i][j] - difference between topic_i and topic_j\n",
      " |      and matrix annotation with shape (m1.num_topics, m2.num_topics, 2, None),\n",
      " |      where:\n",
      " |      \n",
      " |          annotation[i][j] = [[`int_1`, `int_2`, ...], [`diff_1`, `diff_2`, ...]] and\n",
      " |          `int_k` is word from intersection of `topic_i` and `topic_j` and\n",
      " |          `diff_l` is word from symmetric difference of `topic_i` and `topic_j`\n",
      " |          `normed` is a flag. If `true`, matrix Z will be normalized\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      >>> m1, m2 = LdaMulticore.load(path_1), LdaMulticore.load(path_2)\n",
      " |      >>> mdiff, annotation = m1.diff(m2)\n",
      " |      >>> print(mdiff) # get matrix with difference for each topic pair from `m1` and `m2`\n",
      " |      >>> print(annotation) # get array with positive/negative words for each topic pair from `m1` and `m2`\n",
      " |  \n",
      " |  do_estep(self, chunk, state=None)\n",
      " |      Perform inference on a chunk of documents, and accumulate the collected\n",
      " |      sufficient statistics in `state` (or `self.state` if None).\n",
      " |  \n",
      " |  do_mstep(self, rho, other, extra_pass=False)\n",
      " |      M step: use linear interpolation between the existing topics and\n",
      " |      collected sufficient statistics in `other` to update the topics.\n",
      " |  \n",
      " |  get_document_topics(self, bow, minimum_probability=None, minimum_phi_value=None, per_word_topics=False)\n",
      " |      Return topic distribution for the given document `bow`, as a list of\n",
      " |      (topic_id, topic_probability) 2-tuples.\n",
      " |      \n",
      " |      Ignore topics with very low probability (below `minimum_probability`).\n",
      " |      \n",
      " |      If per_word_topics is True, it also returns a list of topics, sorted in descending order of most likely topics for that word.\n",
      " |      It also returns a list of word_ids and each words corresponding topics' phi_values, multiplied by feature length (i.e, word count)\n",
      " |  \n",
      " |  get_term_topics(self, word_id, minimum_probability=None)\n",
      " |      Returns most likely topics for a particular word in vocab.\n",
      " |  \n",
      " |  get_topic_terms(self, topicid, topn=10)\n",
      " |      Return a list of `(word_id, probability)` 2-tuples for the most\n",
      " |      probable words in topic `topicid`.\n",
      " |      \n",
      " |      Only return 2-tuples for the topn most probable words (ignore the rest).\n",
      " |  \n",
      " |  inference(self, chunk, collect_sstats=False)\n",
      " |      Given a chunk of sparse document vectors, estimate gamma (parameters\n",
      " |      controlling the topic weights) for each document in the chunk.\n",
      " |      \n",
      " |      This function does not modify the model (=is read-only aka const). The\n",
      " |      whole input chunk of document is assumed to fit in RAM; chunking of a\n",
      " |      large corpus must be done earlier in the pipeline.\n",
      " |      \n",
      " |      If `collect_sstats` is True, also collect sufficient statistics needed\n",
      " |      to update the model's topic-word distributions, and return a 2-tuple\n",
      " |      `(gamma, sstats)`. Otherwise, return `(gamma, None)`. `gamma` is of shape\n",
      " |      `len(chunk) x self.num_topics`.\n",
      " |      \n",
      " |      Avoids computing the `phi` variational parameter directly using the\n",
      " |      optimization presented in **Lee, Seung: Algorithms for non-negative matrix factorization, NIPS 2001**.\n",
      " |  \n",
      " |  init_dir_prior(self, prior, name)\n",
      " |  \n",
      " |  log_perplexity(self, chunk, total_docs=None)\n",
      " |      Calculate and return per-word likelihood bound, using the `chunk` of\n",
      " |      documents as evaluation corpus. Also output the calculated statistics. incl.\n",
      " |      perplexity=2^(-bound), to log at INFO level.\n",
      " |  \n",
      " |  save(self, fname, ignore=['state', 'dispatcher'], separately=None, *args, **kwargs)\n",
      " |      Save the model to file.\n",
      " |      \n",
      " |      Large internal arrays may be stored into separate files, with `fname` as prefix.\n",
      " |      \n",
      " |      `separately` can be used to define which arrays should be stored in separate files.\n",
      " |      \n",
      " |      `ignore` parameter can be used to define which variables should be ignored, i.e. left\n",
      " |      out from the pickled lda model. By default the internal `state` is ignored as it uses\n",
      " |      its own serialisation not the one provided by `LdaModel`. The `state` and `dispatcher`\n",
      " |      will be added to any ignore parameter defined.\n",
      " |      \n",
      " |      \n",
      " |      Note: do not save as a compressed file if you intend to load the file back with `mmap`.\n",
      " |      \n",
      " |      Note: If you intend to use models across Python 2/3 versions there are a few things to\n",
      " |      keep in mind:\n",
      " |      \n",
      " |        1. The pickled Python dictionaries will not work across Python versions\n",
      " |        2. The `save` method does not automatically save all np arrays using np, only\n",
      " |           those ones that exceed `sep_limit` set in `gensim.utils.SaveLoad.save`. The main\n",
      " |           concern here is the `alpha` array if for instance using `alpha='auto'`.\n",
      " |      \n",
      " |      Please refer to the wiki recipes section (https://github.com/piskvorky/gensim/wiki/Recipes-&-FAQ#q9-how-do-i-load-a-model-in-python-3-that-was-trained-and-saved-using-python-2)\n",
      " |      for an example on how to work around these issues.\n",
      " |  \n",
      " |  show_topic(self, topicid, topn=10)\n",
      " |      Return a list of `(word, probability)` 2-tuples for the most probable\n",
      " |      words in topic `topicid`.\n",
      " |      \n",
      " |      Only return 2-tuples for the topn most probable words (ignore the rest).\n",
      " |  \n",
      " |  show_topics(self, num_topics=10, num_words=10, log=False, formatted=True)\n",
      " |      For `num_topics` number of topics, return `num_words` most significant words\n",
      " |      (10 words per topic, by default).\n",
      " |      \n",
      " |      The topics are returned as a list -- a list of strings if `formatted` is\n",
      " |      True, or a list of `(word, probability)` 2-tuples if False.\n",
      " |      \n",
      " |      If `log` is True, also output this result to log.\n",
      " |      \n",
      " |      Unlike LSA, there is no natural ordering between the topics in LDA.\n",
      " |      The returned `num_topics <= self.num_topics` subset of all topics is therefore\n",
      " |      arbitrary and may change between two LDA training runs.\n",
      " |  \n",
      " |  sync_state(self)\n",
      " |  \n",
      " |  top_topics(self, corpus, num_words=20)\n",
      " |      Calculate the Umass topic coherence for each topic. Algorithm from\n",
      " |      **Mimno, Wallach, Talley, Leenders, McCallum: Optimizing Semantic Coherence in Topic Models, CEMNLP 2011.**\n",
      " |  \n",
      " |  update_alpha(self, gammat, rho)\n",
      " |      Update parameters for the Dirichlet prior on the per-document\n",
      " |      topic weights `alpha` given the last `gammat`.\n",
      " |  \n",
      " |  update_eta(self, lambdat, rho)\n",
      " |      Update parameters for the Dirichlet prior on the per-topic\n",
      " |      word weights `eta` given the last `lambdat`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from gensim.models.ldamodel.LdaModel:\n",
      " |  \n",
      " |  load(fname, *args, **kwargs) from builtins.type\n",
      " |      Load a previously saved object from file (also see `save`).\n",
      " |      \n",
      " |      Large arrays can be memmap'ed back as read-only (shared memory) by setting `mmap='r'`:\n",
      " |      \n",
      " |          >>> LdaModel.load(fname, mmap='r')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gensim.models.basemodel.BaseTopicModel:\n",
      " |  \n",
      " |  print_topic(self, topicno, topn=10)\n",
      " |      Return a single topic as a formatted string. See `show_topic()` for parameters.\n",
      " |      \n",
      " |      >>> lsimodel.print_topic(10, topn=5)\n",
      " |      '-0.340 * \"category\" + 0.298 * \"$M$\" + 0.183 * \"algebra\" + -0.174 * \"functor\" + -0.168 * \"operator\"'\n",
      " |  \n",
      " |  print_topics(self, num_topics=20, num_words=10)\n",
      " |      Alias for `show_topics()` that prints the `num_words` most\n",
      " |      probable words for `topics` number of topics to log.\n",
      " |      Set `topics=-1` to print all topics.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To print the help document for the LDA model class\n",
    "help(lda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The print_topics(n) method of the LDA model object prints out a random sampling of n different learned topics as represented by the most likely terms in the topic's langauge model, i.e. the terms that maximize the topic language model P(term|topic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "nbpresent": {
     "id": "98a57c6a-25fc-4597-9098-5521b9153f5b"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(166,\n",
       "  '0.053*\"history\" + 0.047*\"abortion\" + 0.045*\"honors\" + 0.023*\"declaration\" + 0.021*\"amends_federal_law\" + 0.021*\"content\" + 0.020*\"rescission\" + 0.018*\"weight\" + 0.018*\"save\" + 0.017*\"contains\"'),\n",
       " (14,\n",
       "  '0.040*\"lea\" + 0.024*\"change\" + 0.020*\"civil_rights\" + 0.019*\"immigrant\" + 0.016*\"student\\'s\" + 0.015*\"authorize_the_secretary\" + 0.014*\"spouses\" + 0.014*\"references\" + 0.014*\"withhold\" + 0.014*\"school_year\"'),\n",
       " (50,\n",
       "  '0.131*\"tribal\" + 0.032*\"tribes\" + 0.023*\"band\" + 0.022*\"restricted\" + 0.021*\"replace\" + 0.017*\"hold\" + 0.014*\"united_states\" + 0.014*\"pass\" + 0.012*\"all\" + 0.012*\"jurisdiction\"'),\n",
       " (86,\n",
       "  '0.079*\"travel\" + 0.069*\"initiative\" + 0.035*\"update\" + 0.032*\"fraud\" + 0.027*\"abuse\" + 0.023*\"code\" + 0.022*\"pesticide\" + 0.016*\"society\" + 0.015*\"ethics\" + 0.010*\"travel_expenses\"'),\n",
       " (113,\n",
       "  '0.052*\"women\" + 0.031*\"preservation\" + 0.029*\"boundaries\" + 0.026*\"cultural\" + 0.025*\"boundary\" + 0.022*\"preserve\" + 0.016*\"women\\'s\" + 0.015*\"historical\" + 0.015*\"equity_act\" + 0.014*\"donation\"'),\n",
       " (189,\n",
       "  '0.052*\"firearm\" + 0.040*\"food\" + 0.035*\"risk\" + 0.033*\"exclude\" + 0.031*\"fees\" + 0.016*\"processing\" + 0.014*\"ten_years\" + 0.013*\"act\\'s_enactment\" + 0.013*\"sic\" + 0.013*\"provisions_concerning\"'),\n",
       " (180,\n",
       "  '0.069*\"claim\" + 0.068*\"claims\" + 0.032*\"liability\" + 0.026*\"injury\" + 0.026*\"compensation\" + 0.026*\"loss\" + 0.024*\"settlement\" + 0.021*\"damages\" + 0.017*\"claimant\" + 0.014*\"payment\"'),\n",
       " (192,\n",
       "  '0.171*\"agreement\" + 0.053*\"agreements\" + 0.019*\"parties\" + 0.018*\"enter\" + 0.015*\"entered\" + 0.014*\"union\" + 0.014*\"labor_organization\" + 0.011*\"agree\" + 0.010*\"party\" + 0.009*\"prohibits\"'),\n",
       " (181,\n",
       "  '0.044*\"costs\" + 0.033*\"cost\" + 0.022*\"disaster\" + 0.017*\"fema\" + 0.016*\"repair\" + 0.011*\"restoration\" + 0.010*\"replacement\" + 0.010*\"recovery\" + 0.010*\"reimbursement\" + 0.009*\"costs_incurred\"'),\n",
       " (187,\n",
       "  '0.035*\"board\" + 0.024*\"financial\" + 0.022*\"debt\" + 0.015*\"obligations\" + 0.014*\"bonds\" + 0.013*\"corporation\" + 0.011*\"financial_institutions\" + 0.011*\"banks\" + 0.010*\"bond\" + 0.009*\"deposits\"')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6975bd59-2a7c-466c-b248-7dbff82dea79"
    }
   },
   "source": [
    "#### Infer the Document Probability Score P(topic|doc) using the LDA Model\n",
    "\n",
    "In this section, each document from the corpus is passed into the LDA model which then infers the topic distribution for each document. The topic distributions are collected into a single numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "fe638683-0efb-49b6-93d2-4e8f22f15e6a"
    }
   },
   "outputs": [],
   "source": [
    "# To retrieve all topics and their probabilities we must set the LDA minimum probability setting to zero\n",
    "lda.minimum_probability = 0\n",
    "\n",
    "# This function generates the topic probabilities for each doc from the trained LDA model\n",
    "# The probabilities are placed in a single matrix where the rows are documents and columns are topics\n",
    "def ExtractDocTopicProbsMatrix(corpus,lda):\n",
    "    # Initialize the matrix\n",
    "    docTopicProbs = numpy.zeros((len(corpus),lda.num_topics))\n",
    "    for docID in range(0,len(corpus)):\n",
    "        for topicProb in lda[corpus[docID]]:\n",
    "            docTopicProbs[docID,topicProb[0]]=topicProb[1]\n",
    "    return docTopicProbs    \n",
    "\n",
    "# docTopicProbs[docID,TopicID] --> P(topic|doc)\n",
    "docTopicProbs = ExtractDocTopicProbsMatrix(corpus, lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To save the document topic probabilities to file set this to True:\n",
    "if retrain:\n",
    "    docTopicProbsFile = os.path.join(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'], \"CongressionalDocTopicProbs.npy\")\n",
    "    numpy.save(docTopicProbsFile,docTopicProbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Next\n",
    "\n",
    "The topic modeling step is finished. The next step will be topic model summarization which will be in the fourth notebook of the series: [`4_Topic_Model_Summarization.ipynb`](./4_Topic_Model_Summarization.ipynb)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Document-Collection-Analysis local",
   "language": "python",
   "name": "document-collection-analysis_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {
    "05f2d009-1afe-4edb-8e44-3886ff90f662": {
     "id": "05f2d009-1afe-4edb-8e44-3886ff90f662",
     "prev": "62668528-4383-40d4-8346-55098de21deb",
     "regions": {
      "d017e9eb-469d-4844-a435-8a07fbd34a23": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "1931cc98-9c4c-46c4-bc06-ec37c31944f5",
        "part": "whole"
       },
       "id": "d017e9eb-469d-4844-a435-8a07fbd34a23"
      }
     }
    },
    "0cef4fe0-fb8d-4d04-8499-a0aeb8e39c83": {
     "id": "0cef4fe0-fb8d-4d04-8499-a0aeb8e39c83",
     "prev": "b054cb8c-2fae-45e7-a1ea-5ddf5fafd04b",
     "regions": {
      "dd5ebd19-ba29-416a-93fe-a419a7808320": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "55d8b0a5-11a9-4cf1-8399-b2d036254dd0",
        "part": "whole"
       },
       "id": "dd5ebd19-ba29-416a-93fe-a419a7808320"
      }
     }
    },
    "0e6eef49-e6e3-4a88-81ef-9ca6538de3c7": {
     "id": "0e6eef49-e6e3-4a88-81ef-9ca6538de3c7",
     "prev": "91501d8f-6e03-4eda-bc8e-b30ba3dfc5f0",
     "regions": {
      "c8a095f5-9b2e-49ce-932e-d9e6827b0ce0": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "d3b757c3-d523-4bc0-80af-7be110f7a46e",
        "part": "whole"
       },
       "id": "c8a095f5-9b2e-49ce-932e-d9e6827b0ce0"
      }
     }
    },
    "140f2fe3-3b71-4459-b7b6-6ae13d350899": {
     "id": "140f2fe3-3b71-4459-b7b6-6ae13d350899",
     "prev": "5eea5861-97ec-4b43-9f13-f54553e5f4f8",
     "regions": {
      "add32de8-317f-4069-a350-a458f3c72ccf": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "82e2d906-b067-419d-9532-378c6f36fd69",
        "part": "whole"
       },
       "id": "add32de8-317f-4069-a350-a458f3c72ccf"
      }
     }
    },
    "1776d003-6d9a-4f23-9d96-699132adcd76": {
     "id": "1776d003-6d9a-4f23-9d96-699132adcd76",
     "prev": "53b3e9a4-62db-4c7a-8cfa-fc9f79aee34c",
     "regions": {
      "70125e66-c103-4611-a5da-d3cb44c63b9b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "2152a599-0581-4406-a32c-58b4ff36711a",
        "part": "whole"
       },
       "id": "70125e66-c103-4611-a5da-d3cb44c63b9b"
      }
     }
    },
    "1e29821d-1c4f-4da7-bbe5-c979e7357e74": {
     "id": "1e29821d-1c4f-4da7-bbe5-c979e7357e74",
     "prev": "f71b51d6-502c-4fed-9f1c-1ca9c7856bab",
     "regions": {
      "13a49cd8-72d5-4e60-a7fb-17efba769077": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "23d9b7ef-11db-419b-9f97-7bb07a1e3ca5",
        "part": "whole"
       },
       "id": "13a49cd8-72d5-4e60-a7fb-17efba769077"
      }
     }
    },
    "201e343b-d43c-49a4-b269-144375cc209b": {
     "id": "201e343b-d43c-49a4-b269-144375cc209b",
     "prev": "a8f84401-1564-46ed-9f98-3b5c5587fc2b",
     "regions": {
      "2dfbb0e7-5c43-466a-846c-8b9594885821": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "bc5e3810-08b3-41aa-af97-0159bf9be597",
        "part": "whole"
       },
       "id": "2dfbb0e7-5c43-466a-846c-8b9594885821"
      }
     }
    },
    "2f493bea-47ab-4331-bb67-b54b8e3dc9d3": {
     "id": "2f493bea-47ab-4331-bb67-b54b8e3dc9d3",
     "prev": "140f2fe3-3b71-4459-b7b6-6ae13d350899",
     "regions": {
      "1a39a72b-ce0e-4369-957c-7e6d4d807e6f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7fd9e75d-7abf-4dca-b173-23405ebdfbf6",
        "part": "whole"
       },
       "id": "1a39a72b-ce0e-4369-957c-7e6d4d807e6f"
      }
     }
    },
    "30262120-abbd-4411-bd89-1b5a439d5e3f": {
     "id": "30262120-abbd-4411-bd89-1b5a439d5e3f",
     "prev": "d41619a3-547d-4c04-be26-a5c33b88d40b",
     "regions": {
      "f4b170ee-2f1b-4b02-8766-a2fc64512189": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "46697539-829d-406f-8722-7b4f7ec3beee",
        "part": "whole"
       },
       "id": "f4b170ee-2f1b-4b02-8766-a2fc64512189"
      }
     }
    },
    "331f88b5-9322-49f1-adc5-75ac27be66dd": {
     "id": "331f88b5-9322-49f1-adc5-75ac27be66dd",
     "prev": "0cef4fe0-fb8d-4d04-8499-a0aeb8e39c83",
     "regions": {
      "d01c1b37-6ee0-4b05-8f98-0fdb1810f1e2": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8e615a03-a616-4ce6-aaed-149bb7dc6c41",
        "part": "whole"
       },
       "id": "d01c1b37-6ee0-4b05-8f98-0fdb1810f1e2"
      }
     }
    },
    "34a7e350-fa50-4409-b82e-754894829e6b": {
     "id": "34a7e350-fa50-4409-b82e-754894829e6b",
     "prev": "2f493bea-47ab-4331-bb67-b54b8e3dc9d3",
     "regions": {
      "e155d08e-29ff-43e8-9582-d39d249f8f25": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "688b7bd8-bb00-442d-a195-dd1310424d82",
        "part": "whole"
       },
       "id": "e155d08e-29ff-43e8-9582-d39d249f8f25"
      }
     }
    },
    "363f8c01-8fa5-4d3a-be48-fbe5f510f37f": {
     "id": "363f8c01-8fa5-4d3a-be48-fbe5f510f37f",
     "prev": "bcf6777e-3eda-47d6-b99d-addd1ee0971d",
     "regions": {
      "9bd9bb83-09cf-476f-bf5f-1a626ef786c7": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "1f6a12bd-9325-457d-83d0-9e374033e64f",
        "part": "whole"
       },
       "id": "9bd9bb83-09cf-476f-bf5f-1a626ef786c7"
      }
     }
    },
    "39047648-1076-4f6f-97a9-18850caefd42": {
     "id": "39047648-1076-4f6f-97a9-18850caefd42",
     "prev": "ceb43268-457f-4903-99d1-30e57078a37e",
     "regions": {
      "505fa6dc-a635-4d40-b72f-dcacbd3abbd6": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e537aed2-414b-4e59-be59-5cee147398b5",
        "part": "whole"
       },
       "id": "505fa6dc-a635-4d40-b72f-dcacbd3abbd6"
      }
     }
    },
    "3cda56c3-eb5e-48b8-9212-92a62a2a7826": {
     "id": "3cda56c3-eb5e-48b8-9212-92a62a2a7826",
     "prev": "201e343b-d43c-49a4-b269-144375cc209b",
     "regions": {
      "bd3c7db9-0274-4f8a-8f10-379915d3f716": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c3593bde-7eee-4a9d-8565-7d9774947404",
        "part": "whole"
       },
       "id": "bd3c7db9-0274-4f8a-8f10-379915d3f716"
      }
     }
    },
    "46a01693-1013-42d2-8d91-b3712ff3c87a": {
     "id": "46a01693-1013-42d2-8d91-b3712ff3c87a",
     "prev": "05f2d009-1afe-4edb-8e44-3886ff90f662",
     "regions": {
      "175e092d-bf70-405b-863f-015ab6587671": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fd3d5300-60a1-4873-a52d-a9d5b89b3463",
        "part": "whole"
       },
       "id": "175e092d-bf70-405b-863f-015ab6587671"
      }
     }
    },
    "50e992a5-4a41-4ae5-a900-ef487cd4ae35": {
     "id": "50e992a5-4a41-4ae5-a900-ef487cd4ae35",
     "prev": "574d6678-3a5c-4308-9721-08a400ed1c5c",
     "regions": {
      "ed346ef0-2c3c-4f49-8a7f-2d285a89d18f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "61921e49-660e-4d97-a4c8-feec4804e2ce",
        "part": "whole"
       },
       "id": "ed346ef0-2c3c-4f49-8a7f-2d285a89d18f"
      }
     }
    },
    "51573f2c-47b4-4e58-8d26-c5a4bd5bad73": {
     "id": "51573f2c-47b4-4e58-8d26-c5a4bd5bad73",
     "prev": "5eeee22c-1a7f-4886-9d4e-d2dbf6236f7b",
     "regions": {
      "13c66008-6e50-4845-96bc-ff9377c4c983": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4d17de12-2451-4b0b-ab3b-a73bf7f6e9dc",
        "part": "whole"
       },
       "id": "13c66008-6e50-4845-96bc-ff9377c4c983"
      }
     }
    },
    "53b3e9a4-62db-4c7a-8cfa-fc9f79aee34c": {
     "id": "53b3e9a4-62db-4c7a-8cfa-fc9f79aee34c",
     "prev": "363f8c01-8fa5-4d3a-be48-fbe5f510f37f",
     "regions": {
      "c4999ffb-39fa-4078-b348-70fe2e877a91": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a0086b4c-7e4a-4bc7-b720-7ef6bf2508ad",
        "part": "whole"
       },
       "id": "c4999ffb-39fa-4078-b348-70fe2e877a91"
      }
     }
    },
    "5475c970-b6a6-472c-8c50-5a792b6d7239": {
     "id": "5475c970-b6a6-472c-8c50-5a792b6d7239",
     "prev": "39047648-1076-4f6f-97a9-18850caefd42",
     "regions": {
      "2118fa40-e217-4d08-81d6-6170d4352e71": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "22d6a20f-fa82-4df0-8aac-29c150397a1f",
        "part": "whole"
       },
       "id": "2118fa40-e217-4d08-81d6-6170d4352e71"
      }
     }
    },
    "54fdedeb-5ba3-4a3b-9434-5848640aec04": {
     "id": "54fdedeb-5ba3-4a3b-9434-5848640aec04",
     "prev": "b6bd6bfd-15ba-42b0-8c9f-0c7da3f2c412",
     "regions": {
      "85dd6a4b-89d5-4d2a-9ec2-b921fb785e59": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fe638683-0efb-49b6-93d2-4e8f22f15e6a",
        "part": "whole"
       },
       "id": "85dd6a4b-89d5-4d2a-9ec2-b921fb785e59"
      }
     }
    },
    "565b4230-1376-4e7c-a13e-b4995b8a0bba": {
     "id": "565b4230-1376-4e7c-a13e-b4995b8a0bba",
     "prev": "34a7e350-fa50-4409-b82e-754894829e6b",
     "regions": {
      "ebc439f8-9559-4dee-8a5d-ae06b3d11bf2": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ac3b8bc5-6733-46cf-9451-10b7c9ef8d88",
        "part": "whole"
       },
       "id": "ebc439f8-9559-4dee-8a5d-ae06b3d11bf2"
      }
     }
    },
    "574d6678-3a5c-4308-9721-08a400ed1c5c": {
     "id": "574d6678-3a5c-4308-9721-08a400ed1c5c",
     "prev": "46a01693-1013-42d2-8d91-b3712ff3c87a",
     "regions": {
      "bef7e15a-4149-459d-a43e-b10ac158063c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f2b0a490-a67d-47fc-872f-1e4696886ecb",
        "part": "whole"
       },
       "id": "bef7e15a-4149-459d-a43e-b10ac158063c"
      }
     }
    },
    "576b393a-49c9-418c-88c8-d809cf395f9b": {
     "id": "576b393a-49c9-418c-88c8-d809cf395f9b",
     "prev": "f352183b-c020-4e8d-b0c5-22bee23dc2fe",
     "regions": {
      "34336a75-959c-449a-ac26-326f6f712351": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "eaf0b191-c85a-48b9-9bcb-b38ca076c9b4",
        "part": "whole"
       },
       "id": "34336a75-959c-449a-ac26-326f6f712351"
      }
     }
    },
    "57f789db-05dd-4bf0-8526-3c0ad9fe84ef": {
     "id": "57f789db-05dd-4bf0-8526-3c0ad9fe84ef",
     "prev": "a3a6270c-ba38-4a61-9885-cdcefc707993",
     "regions": {
      "10fbe879-f4ba-42f8-a10f-c2d794f23a9a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c158c2fc-56b7-40a7-a765-d7a3b4692839",
        "part": "whole"
       },
       "id": "10fbe879-f4ba-42f8-a10f-c2d794f23a9a"
      }
     }
    },
    "5eea5861-97ec-4b43-9f13-f54553e5f4f8": {
     "id": "5eea5861-97ec-4b43-9f13-f54553e5f4f8",
     "prev": "f7603915-d5b5-4c40-b10a-08bb21bc64bc",
     "regions": {
      "60f7cfd2-412d-45ca-b9f3-288ec1d241d6": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b43ca7bd-75e7-4d17-9f77-80ce05375dad",
        "part": "whole"
       },
       "id": "60f7cfd2-412d-45ca-b9f3-288ec1d241d6"
      }
     }
    },
    "5eeee22c-1a7f-4886-9d4e-d2dbf6236f7b": {
     "id": "5eeee22c-1a7f-4886-9d4e-d2dbf6236f7b",
     "prev": "1776d003-6d9a-4f23-9d96-699132adcd76",
     "regions": {
      "b8223200-f30d-44c0-b41e-0a0db1825253": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a726551f-3724-4de9-87d5-0c0418852da4",
        "part": "whole"
       },
       "id": "b8223200-f30d-44c0-b41e-0a0db1825253"
      }
     }
    },
    "62668528-4383-40d4-8346-55098de21deb": {
     "id": "62668528-4383-40d4-8346-55098de21deb",
     "prev": "c1a57d7c-99c7-4e52-812c-cf2c74664e55",
     "regions": {
      "cd307f23-6a10-474d-a0b2-839f698fa5c6": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ec8066e8-9812-4956-b76a-8a4d0086385c",
        "part": "whole"
       },
       "id": "cd307f23-6a10-474d-a0b2-839f698fa5c6"
      }
     }
    },
    "65d70995-6916-4f25-a4bd-b09969de74ce": {
     "id": "65d70995-6916-4f25-a4bd-b09969de74ce",
     "prev": "3cda56c3-eb5e-48b8-9212-92a62a2a7826",
     "regions": {
      "2637e2e8-d300-488e-8580-f43e05610a39": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "21678e5f-ad6c-46d1-8a71-f64bd9483c42",
        "part": "whole"
       },
       "id": "2637e2e8-d300-488e-8580-f43e05610a39"
      }
     }
    },
    "70e3ee2e-bfe6-4f43-af9c-6346661e54c5": {
     "id": "70e3ee2e-bfe6-4f43-af9c-6346661e54c5",
     "prev": "8aec0b7f-1025-41b7-bc0d-aa8c4448ca70",
     "regions": {
      "f9c404d5-84d6-41b9-baa3-f66373330ff2": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "bc5ecdb1-c51c-457f-be3f-eee94247f13b",
        "part": "whole"
       },
       "id": "f9c404d5-84d6-41b9-baa3-f66373330ff2"
      }
     }
    },
    "8a4c7762-739d-4b1e-9e82-c1ab40edf5b5": {
     "id": "8a4c7762-739d-4b1e-9e82-c1ab40edf5b5",
     "prev": "565b4230-1376-4e7c-a13e-b4995b8a0bba",
     "regions": {
      "c91c6488-bd1d-4243-bd8b-a5c7b3df186c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e45a357e-ab67-4d85-80e9-d433714f9798",
        "part": "whole"
       },
       "id": "c91c6488-bd1d-4243-bd8b-a5c7b3df186c"
      }
     }
    },
    "8aec0b7f-1025-41b7-bc0d-aa8c4448ca70": {
     "id": "8aec0b7f-1025-41b7-bc0d-aa8c4448ca70",
     "prev": "30262120-abbd-4411-bd89-1b5a439d5e3f",
     "regions": {
      "8b5fc013-d5ba-4eb4-97d7-8332986ca2d9": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fb58ed5d-85bb-4ab3-9b8e-2d8b79d2df55",
        "part": "whole"
       },
       "id": "8b5fc013-d5ba-4eb4-97d7-8332986ca2d9"
      }
     }
    },
    "91501d8f-6e03-4eda-bc8e-b30ba3dfc5f0": {
     "id": "91501d8f-6e03-4eda-bc8e-b30ba3dfc5f0",
     "prev": "51573f2c-47b4-4e58-8d26-c5a4bd5bad73",
     "regions": {
      "09a4f864-d729-4241-b38e-f177c8dd729e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c96b2d58-4729-4243-8799-c21dc615fa58",
        "part": "whole"
       },
       "id": "09a4f864-d729-4241-b38e-f177c8dd729e"
      }
     }
    },
    "98743de2-1c1e-48ad-af4c-1f5af339092a": {
     "id": "98743de2-1c1e-48ad-af4c-1f5af339092a",
     "prev": "65d70995-6916-4f25-a4bd-b09969de74ce",
     "regions": {
      "7bf9c7ba-0f21-4335-8e2f-c1167cb2713e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4ddff9a8-0a31-4889-bedb-b64d10eddcc1",
        "part": "whole"
       },
       "id": "7bf9c7ba-0f21-4335-8e2f-c1167cb2713e"
      }
     }
    },
    "9b722714-7a0c-41fe-a2ea-7a1065f9fcfb": {
     "id": "9b722714-7a0c-41fe-a2ea-7a1065f9fcfb",
     "prev": null,
     "regions": {
      "c2409342-142e-4490-99ab-2bd221db4aba": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "31b17f54-6bfd-48da-ade1-d08773cc47f1",
        "part": "whole"
       },
       "id": "c2409342-142e-4490-99ab-2bd221db4aba"
      }
     }
    },
    "a3a6270c-ba38-4a61-9885-cdcefc707993": {
     "id": "a3a6270c-ba38-4a61-9885-cdcefc707993",
     "prev": "a7232942-629c-40bc-a9f6-2843f15aa652",
     "regions": {
      "8c3ed09e-4098-4a54-8d79-f0f3145629b0": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f28084b0-cc2e-4231-842f-5765d92d44f0",
        "part": "whole"
       },
       "id": "8c3ed09e-4098-4a54-8d79-f0f3145629b0"
      }
     }
    },
    "a7232942-629c-40bc-a9f6-2843f15aa652": {
     "id": "a7232942-629c-40bc-a9f6-2843f15aa652",
     "prev": "f4146329-5a8f-4afa-b173-bf72e045d2e2",
     "regions": {
      "cbd01583-9fdc-45aa-86fd-66e5acdc068a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6244226e-a91b-4767-83da-d41e882399a4",
        "part": "whole"
       },
       "id": "cbd01583-9fdc-45aa-86fd-66e5acdc068a"
      }
     }
    },
    "a8b9740f-17bf-4874-854a-81138b906f1e": {
     "id": "a8b9740f-17bf-4874-854a-81138b906f1e",
     "prev": "ccb90a10-a80d-478d-b925-2bc0c979183e",
     "regions": {
      "9df434d3-a4fe-4d81-8b5f-2711cf8c285e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "bbe5cc20-ad4f-482c-8f94-09de87752d30",
        "part": "whole"
       },
       "id": "9df434d3-a4fe-4d81-8b5f-2711cf8c285e"
      }
     }
    },
    "a8f84401-1564-46ed-9f98-3b5c5587fc2b": {
     "id": "a8f84401-1564-46ed-9f98-3b5c5587fc2b",
     "prev": "70e3ee2e-bfe6-4f43-af9c-6346661e54c5",
     "regions": {
      "0f60d3c1-372d-40d6-b59e-ad867e1c63f6": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8a9b81d1-058f-4a37-acbe-b825045866b4",
        "part": "whole"
       },
       "id": "0f60d3c1-372d-40d6-b59e-ad867e1c63f6"
      }
     }
    },
    "b054cb8c-2fae-45e7-a1ea-5ddf5fafd04b": {
     "id": "b054cb8c-2fae-45e7-a1ea-5ddf5fafd04b",
     "prev": "98743de2-1c1e-48ad-af4c-1f5af339092a",
     "regions": {
      "e21ecc9f-a912-45da-96a2-b4d1f970628e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "177ee67d-3e38-4009-b65e-4d08f79c862b",
        "part": "whole"
       },
       "id": "e21ecc9f-a912-45da-96a2-b4d1f970628e"
      }
     }
    },
    "b6bd6bfd-15ba-42b0-8c9f-0c7da3f2c412": {
     "id": "b6bd6bfd-15ba-42b0-8c9f-0c7da3f2c412",
     "prev": "da843dce-021d-471b-a542-f4b8d2591a62",
     "regions": {
      "6550d1d6-e978-43e5-9e79-6f7d4a718cd4": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6975bd59-2a7c-466c-b248-7dbff82dea79",
        "part": "whole"
       },
       "id": "6550d1d6-e978-43e5-9e79-6f7d4a718cd4"
      }
     }
    },
    "ba74b38b-6de6-4f16-b7b1-bb78365fee8a": {
     "id": "ba74b38b-6de6-4f16-b7b1-bb78365fee8a",
     "prev": "cf0820e2-9708-4c69-96e1-cfaab18170b6",
     "regions": {
      "a109cf38-42d4-49f1-b5c3-e5d95e13a5f3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "5fef2737-5cde-43e2-8c05-04320722da93",
        "part": "whole"
       },
       "id": "a109cf38-42d4-49f1-b5c3-e5d95e13a5f3"
      }
     }
    },
    "bbc708aa-4a8b-4aae-bd36-7dbe87a4172d": {
     "id": "bbc708aa-4a8b-4aae-bd36-7dbe87a4172d",
     "prev": "0e6eef49-e6e3-4a88-81ef-9ca6538de3c7",
     "regions": {
      "306c285e-6439-4773-be85-1d6b90b44dcb": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "96008087-cb6e-4ba1-b9c6-b4480835ef0f",
        "part": "whole"
       },
       "id": "306c285e-6439-4773-be85-1d6b90b44dcb"
      }
     }
    },
    "bcf6777e-3eda-47d6-b99d-addd1ee0971d": {
     "id": "bcf6777e-3eda-47d6-b99d-addd1ee0971d",
     "prev": "576b393a-49c9-418c-88c8-d809cf395f9b",
     "regions": {
      "fd7ec647-ff66-4fc9-b026-508f4f73fd73": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "bcd1daea-0849-4cd4-9349-a7f52641eb95",
        "part": "whole"
       },
       "id": "fd7ec647-ff66-4fc9-b026-508f4f73fd73"
      }
     }
    },
    "c1a57d7c-99c7-4e52-812c-cf2c74664e55": {
     "id": "c1a57d7c-99c7-4e52-812c-cf2c74664e55",
     "prev": "8a4c7762-739d-4b1e-9e82-c1ab40edf5b5",
     "regions": {
      "1981b742-5951-4860-9e99-bbd9c5ba71a8": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9c6d2ec8-2fd6-43ac-89e7-293228019bb2",
        "part": "whole"
       },
       "id": "1981b742-5951-4860-9e99-bbd9c5ba71a8"
      }
     }
    },
    "c27308f0-bd6b-4b36-8ff1-6ce863894538": {
     "id": "c27308f0-bd6b-4b36-8ff1-6ce863894538",
     "prev": "cb39cf50-e059-426b-b314-52968b249608",
     "regions": {
      "d9d1c211-e2e4-4242-a9ac-6186c72f7fb9": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a9d68eeb-a68b-487f-8fb9-088168cddbda",
        "part": "whole"
       },
       "id": "d9d1c211-e2e4-4242-a9ac-6186c72f7fb9"
      }
     }
    },
    "cb39cf50-e059-426b-b314-52968b249608": {
     "id": "cb39cf50-e059-426b-b314-52968b249608",
     "prev": "a8b9740f-17bf-4874-854a-81138b906f1e",
     "regions": {
      "7d1736b5-d6db-49ea-bb88-d6240a63bf60": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "dacd12f0-444b-4759-af58-27d4ba1c4fe5",
        "part": "whole"
       },
       "id": "7d1736b5-d6db-49ea-bb88-d6240a63bf60"
      }
     }
    },
    "cb89c63b-a2fd-4e72-b76c-7fc44dd7b6be": {
     "id": "cb89c63b-a2fd-4e72-b76c-7fc44dd7b6be",
     "prev": "bbc708aa-4a8b-4aae-bd36-7dbe87a4172d",
     "regions": {
      "d012c252-7d7b-4633-985d-873edc19d5bc": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "2a72aece-5261-4bad-883b-b21455f957cc",
        "part": "whole"
       },
       "id": "d012c252-7d7b-4633-985d-873edc19d5bc"
      }
     }
    },
    "ccb90a10-a80d-478d-b925-2bc0c979183e": {
     "id": "ccb90a10-a80d-478d-b925-2bc0c979183e",
     "prev": "ba74b38b-6de6-4f16-b7b1-bb78365fee8a",
     "regions": {
      "231f19ab-00e3-47fa-9cd3-cfc74bca54b3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "31b80b11-4918-48ac-a513-974a85830a0a",
        "part": "whole"
       },
       "id": "231f19ab-00e3-47fa-9cd3-cfc74bca54b3"
      }
     }
    },
    "ceb43268-457f-4903-99d1-30e57078a37e": {
     "id": "ceb43268-457f-4903-99d1-30e57078a37e",
     "prev": "331f88b5-9322-49f1-adc5-75ac27be66dd",
     "regions": {
      "f1f8982d-80e7-4081-b787-451ad5a723e7": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "1301be86-24d2-45a3-aced-d0b4948e765b",
        "part": "whole"
       },
       "id": "f1f8982d-80e7-4081-b787-451ad5a723e7"
      }
     }
    },
    "cf0820e2-9708-4c69-96e1-cfaab18170b6": {
     "id": "cf0820e2-9708-4c69-96e1-cfaab18170b6",
     "prev": "50e992a5-4a41-4ae5-a900-ef487cd4ae35",
     "regions": {
      "b052b2ed-acc4-491e-a9c1-4c418029bacf": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "902f0953-1cc3-465a-a93b-aa08daf2b18b",
        "part": "whole"
       },
       "id": "b052b2ed-acc4-491e-a9c1-4c418029bacf"
      }
     }
    },
    "d41619a3-547d-4c04-be26-a5c33b88d40b": {
     "id": "d41619a3-547d-4c04-be26-a5c33b88d40b",
     "prev": "1e29821d-1c4f-4da7-bbe5-c979e7357e74",
     "regions": {
      "83fa0715-62ef-41ce-a8be-7e7e9f45a4a1": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "44f6c13e-aae6-4bcf-97f5-5527bacc0512",
        "part": "whole"
       },
       "id": "83fa0715-62ef-41ce-a8be-7e7e9f45a4a1"
      }
     }
    },
    "da843dce-021d-471b-a542-f4b8d2591a62": {
     "id": "da843dce-021d-471b-a542-f4b8d2591a62",
     "prev": "cb89c63b-a2fd-4e72-b76c-7fc44dd7b6be",
     "regions": {
      "588d63ad-348c-4393-bff0-7983fbc6fb98": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "98a57c6a-25fc-4597-9098-5521b9153f5b",
        "part": "whole"
       },
       "id": "588d63ad-348c-4393-bff0-7983fbc6fb98"
      }
     }
    },
    "f352183b-c020-4e8d-b0c5-22bee23dc2fe": {
     "id": "f352183b-c020-4e8d-b0c5-22bee23dc2fe",
     "prev": "57f789db-05dd-4bf0-8526-3c0ad9fe84ef",
     "regions": {
      "e60b3552-f330-4638-8dd6-2641f172504f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "be794056-435f-49e2-b69b-2ca5409710bf",
        "part": "whole"
       },
       "id": "e60b3552-f330-4638-8dd6-2641f172504f"
      }
     }
    },
    "f4146329-5a8f-4afa-b173-bf72e045d2e2": {
     "id": "f4146329-5a8f-4afa-b173-bf72e045d2e2",
     "prev": "5475c970-b6a6-472c-8c50-5a792b6d7239",
     "regions": {
      "71d82122-be41-4ecf-b333-56d798905c13": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "1940dcd6-9b8b-4dea-af39-ca75e72062aa",
        "part": "whole"
       },
       "id": "71d82122-be41-4ecf-b333-56d798905c13"
      }
     }
    },
    "f71b51d6-502c-4fed-9f1c-1ca9c7856bab": {
     "id": "f71b51d6-502c-4fed-9f1c-1ca9c7856bab",
     "prev": "9b722714-7a0c-41fe-a2ea-7a1065f9fcfb",
     "regions": {
      "1db50964-9f01-4c97-9d5b-778c2bcdb4bf": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "21d8d7fd-501d-4eec-abd4-a827100e5406",
        "part": "whole"
       },
       "id": "1db50964-9f01-4c97-9d5b-778c2bcdb4bf"
      }
     }
    },
    "f7603915-d5b5-4c40-b10a-08bb21bc64bc": {
     "id": "f7603915-d5b5-4c40-b10a-08bb21bc64bc",
     "prev": "54fdedeb-5ba3-4a3b-9434-5848640aec04",
     "regions": {
      "1c520645-43cc-4a54-a8b7-869917f8d407": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "65904084-4721-4b58-8ea5-711b7b6388fa",
        "part": "whole"
       },
       "id": "1c520645-43cc-4a54-a8b7-869917f8d407"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
